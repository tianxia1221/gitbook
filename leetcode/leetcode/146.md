[TOC]

# 146. LRU Cache

> https://leetcode.com/problems/lru-cache/

> Design and implement a data structure for [Least Recently Used (LRU) cache](https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU). It should support the following operations: `get` and `put`.
>
> `get(key)` - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.
> `put(key, value)` - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.
>
> The cache is initialized with a **positive** capacity.

## Approach 1:  Double Linked List + HashMap

```java
class LRUCache {
    private class Node {
        int key, value;
        Node prev, next;

        Node(int k, int v) {
            this.key = k;
            this.value = v;
        }

        Node() {
            this(0, 0);
        }
    }

    private int capacity, count;
    private Map<Integer, Node> map;
    private Node head, tail;

    public LRUCache(int capacity) {
        this.capacity = capacity;
        head = new Node();
        tail = new Node();

        head.next = tail;
        tail.prev = head;
        count = 0;
        map = new HashMap<>();
    }

    public int get(int key) {
        Node n = map.get(key);
        if (n == null) {
            return -1;
        }
        update(n);
        return n.value;

    }

    public void put(int key, int value) {
        Node n = map.get(key);
        if (n != null) {
            n.value = value;
            update(n);
            return;
        }

        if (capacity <= count) {
            Node del = tail.prev;
            remove(del);
            map.remove(del.key);
        }

        Node node = new Node(key, value);
        map.put(key, node);
        add(node);
        count++;
    }

    private void add(Node node) {
        Node n = head.next;
        n.prev = node;
        node.next = n;
        node.prev = head;
        head.next = node;
    }

    private void remove(Node node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }

    private void update(Node node) {
        remove(node);
        add(node);
    }

}

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache obj = new LRUCache(capacity);
 * int param_1 = obj.get(key);
 * obj.put(key,value);
 */
```

> Runtime: 11 ms, faster than 99.97% of Java online submissions for LRU Cache.
>
> Memory Usage: 50.1 MB, less than 97.55% of Java online submissions for LRU Cache.

## Approach 2: Java  LinkedHashMap

```java
class LRUCache { 
    private LinkedHashMap<Integer, Integer> cache;
    private int capacity; 
    
    public LRUCache(int capacity) {
        
        //create cache with initial capacity of 16 items, load factor of 75% and using access order (LRU style) retrieval
        this.cache = new LinkedHashMap<Integer, Integer>(16,0.75f,true){
            
            //anonymous inner class to override removeEldestEntry behaivor. 
            @Override
            protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
                return  cache.size() > capacity;
            }
        };
        this.capacity = capacity;
    }
    
    public int get(int key) {
        int value = cache.getOrDefault(key, -1);
        return value;
    } 
    
    public void put(int key, int value) {  
        cache.put(key, value);  
    }
}
```

> Runtime: 12 ms, faster than 99.79% of Java online submissions for LRU Cache.
>
> Memory Usage: 50.5 MB, less than 97.55% of Java online submissions for LRU Cache.